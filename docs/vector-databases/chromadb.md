---
title: Chroma
---

:::info Developer Notice

Chroma [requires a server](https://docs.trychroma.com/usage-guide#running-chroma-in-clientserver-mode) to be running so that Chroma can embed or index your embeddings automatically. AnythingLLM will use the embedding model set and **will not** use Chroma's built-in embedders even if defined.

:::

[Chroma](https://trychroma.com) is an [open-source](https://github.com/chroma-core/chroma) and ai-native vector database that is easy to run and host anywhere.

AnythingLLM can connect to your local or cloud-hosted Chroma instance running so that AnythingLLM can store and search embeddings on it automatically.


### How to run Chroma Locally via Docker

<iframe width="800" height="500" src="https://www.youtube.com/embed/61kaK-e3Owc?si=AIf-ovmuNrWoE743" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>