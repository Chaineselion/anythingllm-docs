The easiest way to use LocalAI with AnythingLLM is to use the **Midori AI** single-image installer. This **community-built** installer will install _LocalAI_ + _AnythingLLM_ in a single installer and is much easier than installing both systems independently!

ðŸ‘‰ Check it out at [https://io.midori-ai.xyz/howtos/easy-localai-installer/](https://io.midori-ai.xyz/howtos/easy-localai-installer/)

[LocalAi ](https://localai.io)is a fully-featured CLI application that you can run to easily spin up an API server for chatting with open-source models found on [HuggingFace](https://huggingface.com) as well as running embedding models!





AnythingLLM supports the use of a private API key for accessing your LocalAI API!

You are responsible for running and maintaining your instance of LocalAI so that AnythingLLM can chat with it and use it for generative responses and embeddings

![](files/A0XnNzZgud6jS81SOxsG.png)

Like other LLM providers, the Chat Model Selection dropdown will automatically populate when your key is entered. All models in your installation will be available to you for chatting.

